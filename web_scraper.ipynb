{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "novel-compact",
   "metadata": {},
   "source": [
    "#### Building a webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-lucas",
   "metadata": {},
   "source": [
    "Using requests module to read the contents of the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "burning-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "european-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\t<head>\n",
      "\t\t<!-- Anti-flicker snippet (recommended)  -->\n",
      "\t\t<style>\n",
      "\t\t\t.async-hide {\n",
      "\t\t\t\topacity: 0 !important;\n",
      "\t\t\t}\n",
      "\t\t</style>\n",
      "\t\t<title>codedamn Web Scraper demo</title> 200\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(\"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "text = res.text\n",
    "status = res.status_code\n",
    "\n",
    "print(text[:200], status) # limiting the amount of text printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thorough-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  conda install -c anaconda beautifulsoup4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-convenience",
   "metadata": {},
   "source": [
    "Importing module BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "robust-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-airline",
   "metadata": {},
   "source": [
    "Extracting ```title``` from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monetary-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://codedamn.com\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "title = soup.title.text # gets the text of the <title>(...)</title>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bigger-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codedamn - Learn coding like it's 2026\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "colored-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the body of the page\n",
    "body = soup.body\n",
    "\n",
    "# Extracting head of the page\n",
    "head = soup.head\n",
    "\n",
    "# print the body and head\n",
    "# print(body, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-progressive",
   "metadata": {},
   "source": [
    "Using the ```.select``` to select elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apart-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first <h1>(...)</h1>text\n",
    "first_h1 = soup.select('h1')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outdoor-associate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn web development with mentorship, hands-on practice, and courses.\n"
     ]
    }
   ],
   "source": [
    "print(first_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "distinct-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Perfect Practice Environment', ' Browse from a laptop/desktop to experience demo', '\"Video courses\" don\\'t work alone.', 'Learning Path'] \n",
      "=============\n",
      " Our frontend web developer learning path covers everything you need to know, including industry-specific questions/hands-on practice exercises along with HD video courses from top creators.This comes with mentorship support if you're signed up for 1337 membership.\n"
     ]
    }
   ],
   "source": [
    "#creating an empty list to hold all h2_tags\n",
    "all_h2_tags = []\n",
    "\n",
    "# Append all h1 tags to all_h2_tags\n",
    "for element in soup.select('h2'):\n",
    "    all_h2_tags.append(element.text)\n",
    "\n",
    "# Select 7th p element\n",
    "seventh_p_text = soup.select('p')[6].text\n",
    "\n",
    "print(all_h2_tags, \"\\n=============\\n\", seventh_p_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-shift",
   "metadata": {},
   "source": [
    "Extracting specific inner texts from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "referenced-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Asus AsusPro Adv...', 'review': '7 reviews'}, {'title': 'Asus ROG Strix G...', 'review': '4 reviews'}, {'title': 'Acer Aspire 3 A3...', 'review': '2 reviews'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# make a request\n",
    "page = requests.get(\n",
    "            \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# create top_items as empty list\n",
    "top_items = []\n",
    "\n",
    "# Extract and store in top_items\n",
    "products = soup.select('div.thumbnail')\n",
    "for element in products:\n",
    "    title = element.select('h4 > a.title')[0].text\n",
    "    review_label = element.select('div.ratings')[0].text\n",
    "    info = {\n",
    "        \"title\" : title.strip(),\n",
    "        \"review\": review_label.strip()\n",
    "    }\n",
    "    top_items.append(info)\n",
    "\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-bangkok",
   "metadata": {},
   "source": [
    "#### Extracting Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-nightmare",
   "metadata": {},
   "source": [
    "Getting image data from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lightweight-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'src': '/webscraper-python-codedamn-classroom-website/logo_white.svg', 'alt': 'Web Scraper'}, {'src': '/webscraper-python-codedamn-classroom-website/cart2.png', 'alt': 'item'}, {'src': '/webscraper-python-codedamn-classroom-website/cart2.png', 'alt': 'item'}, {'src': '/webscraper-python-codedamn-classroom-website/cart2.png', 'alt': 'item'}, {'src': '/webscraper-python-codedamn-classroom-website/fbicon.png', 'alt': 'Web Scraper on Facebook'}, {'src': '/webscraper-python-codedamn-classroom-website/twicon.png', 'alt': 'Web Scraper on Twitter'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# make a request\n",
    "page = requests.get(\n",
    "            \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# create image_data as empty list\n",
    "image_data = []\n",
    "\n",
    "# Extract and save images to image_data\n",
    "images = soup.select('img')\n",
    "for image in images:\n",
    "    src = image.get('src')\n",
    "    alt = image.get('alt')\n",
    "    image_data.append({\"src\": src, \"alt\": alt})\n",
    "    \n",
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "peaceful-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'href': '', 'text': 'Toggle navigation'}, {'href': '/webscraper-python-codedamn-classroom-website/', 'text': ''}, {'href': '#page-top', 'text': ''}, {'href': '/webscraper-python-codedamn-classroom-website/', 'text': 'Web Scraper'}, {'href': '/webscraper-python-codedamn-classroom-website/cloud-scraper', 'text': 'Cloud Scraper'}, {'href': '/webscraper-python-codedamn-classroom-website/pricing', 'text': 'Pricing'}, {'href': '#section3', 'text': 'Learn'}, {'href': '/webscraper-python-codedamn-classroom-website/documentation', 'text': 'Documentation'}, {'href': '/webscraper-python-codedamn-classroom-website/tutorials', 'text': 'Video Tutorials'}, {'href': '/webscraper-python-codedamn-classroom-website/how-to-videos', 'text': 'How to'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites', 'text': 'Test Sites'}, {'href': 'https://forum.webscraper.io/', 'text': 'Forum'}, {'href': 'https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn?hl=en', 'text': 'Install'}, {'href': 'https://cloud.webscraper.io/', 'text': 'Login'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone', 'text': 'Home'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/computers', 'text': 'Computers'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/phones', 'text': 'Phones'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/593', 'text': 'Asus AsusPro Adv...'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/583', 'text': 'Asus ROG Strix G...'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/576', 'text': 'Acer Aspire 3 A3...'}, {'href': '/webscraper-python-codedamn-classroom-website/', 'text': 'Web Scraper browser extension'}, {'href': '/webscraper-python-codedamn-classroom-website/pricing', 'text': 'Web Scraper Cloud'}, {'href': '/webscraper-python-codedamn-classroom-website/contact', 'text': 'Contact'}, {'href': '/webscraper-python-codedamn-classroom-website/privacy-policy', 'text': 'Website Privacy Policy'}, {'href': '/webscraper-python-codedamn-classroom-website/extension-privacy-policy', 'text': 'Browser Extension Privacy Policy'}, {'href': 'http://webscraperio.us-east-1.elasticbeanstalk.com/downloads/Web_Scraper_Media_Kit.zip', 'text': 'Media kit'}, {'href': '/webscraper-python-codedamn-classroom-website/jobs', 'text': 'Jobs'}, {'href': '/webscraper-python-codedamn-classroom-website/blog', 'text': 'Blog'}, {'href': '/webscraper-python-codedamn-classroom-website/documentation', 'text': 'Documentation'}, {'href': '/webscraper-python-codedamn-classroom-website/tutorials', 'text': 'Video Tutorials'}, {'href': '/webscraper-python-codedamn-classroom-website/screenshots', 'text': 'Screenshots'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites', 'text': 'Test Sites'}, {'href': 'https://forum.webscraper.io/', 'text': 'Forum'}, {'href': 'mailto:info@webscraper.io', 'text': 'info@webscraper.io'}, {'href': 'https://www.facebook.com/webscraperio/', 'text': ''}, {'href': 'https://twitter.com/webscraperio', 'text': ''}, {'href': '#', 'text': 'Web Scraper'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# make a request \n",
    "page = requests.get(\n",
    "                \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Create all_items as empty list\n",
    "all_links = []\n",
    "\n",
    "# Extract and store items\n",
    "links = soup.select('a')\n",
    "for ahref in links:\n",
    "    text = ahref.text\n",
    "    text = text.strip() if text is not None else \"\"\n",
    "    \n",
    "    href = ahref.get('href')\n",
    "    href = href.strip() if href is not None else \"\"\n",
    "    all_links.append({\"href\": href, \"text\": text})\n",
    "    \n",
    "print(all_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-decision",
   "metadata": {},
   "source": [
    "#### Extracting data and creating a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "turned-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "page = requests.get(\n",
    "            \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# create empty list to hold items\n",
    "all_products = []\n",
    "\n",
    "# Extract desired items from the webpage\n",
    "products = soup.select('div.thumbnail')\n",
    "for product in products:\n",
    "    name = product.select('h4 > a')[0].text.strip()\n",
    "    description = product.select('p.description')[0].text.strip()\n",
    "    price = product.select('h4.price')[0].text.strip()\n",
    "    reviews = product.select('div.ratings')[0].text.strip()\n",
    "    image = product.select('img')[0].get('src')\n",
    "    \n",
    "    all_products.append({\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"price\": price,\n",
    "        \"reviews\": reviews,\n",
    "        \"image\": image\n",
    "    })\n",
    "    \n",
    "keys = all_products[0].keys()\n",
    "\n",
    "with open('products.csv', 'w', newline=\"\") as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(all_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-battle",
   "metadata": {},
   "source": [
    "Reading the newly created ```.csv``` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "rough-racing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>reviews</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus AsusPro Adv...</td>\n",
       "      <td>Asus AsusPro Advanced BU401LA-FA271G Dark Grey...</td>\n",
       "      <td>$1139.54</td>\n",
       "      <td>7 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asus ROG Strix G...</td>\n",
       "      <td>Apple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, ...</td>\n",
       "      <td>$1101.83</td>\n",
       "      <td>4 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Aspire 3 A3...</td>\n",
       "      <td>Acer Aspire 3 A315-51 Black, 15.6\" FHD, Core\\n...</td>\n",
       "      <td>$494.71</td>\n",
       "      <td>2 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                        description  \\\n",
       "0  Asus AsusPro Adv...  Asus AsusPro Advanced BU401LA-FA271G Dark Grey...   \n",
       "1  Asus ROG Strix G...  Apple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, ...   \n",
       "2  Acer Aspire 3 A3...  Acer Aspire 3 A315-51 Black, 15.6\" FHD, Core\\n...   \n",
       "\n",
       "      price    reviews                                              image  \n",
       "0  $1139.54  7 reviews  /webscraper-python-codedamn-classroom-website/...  \n",
       "1  $1101.83  4 reviews  /webscraper-python-codedamn-classroom-website/...  \n",
       "2   $494.71  2 reviews  /webscraper-python-codedamn-classroom-website/...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('products.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-mailing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
